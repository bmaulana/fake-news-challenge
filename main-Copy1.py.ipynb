{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from data.scorer import score_submission, print_confusion_matrix, score_defaults, SCORE_REPORT\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "f_bodies = open('data/train_bodies.csv', 'r', encoding='utf-8')\n",
    "csv_bodies = csv.DictReader(f_bodies)\n",
    "bodies = []\n",
    "for row in csv_bodies:\n",
    "    body_id = int(row['Body ID'])\n",
    "    if (body_id + 1) > len(bodies):\n",
    "        bodies += [None] * (body_id + 1 - len(bodies))\n",
    "    bodies[body_id] = row['articleBody']\n",
    "f_bodies.close()\n",
    "body_inverse_index = {bodies[i]: i for i in range(len(bodies))}\n",
    "\n",
    "all_unrelated, all_discuss, all_agree, all_disagree = [], [], [], []  # each article = (headline, body, stance)\n",
    "\n",
    "f_stances = open('data/train_stances.csv', 'r', encoding='utf-8')\n",
    "csv_stances = csv.DictReader(f_stances)\n",
    "for row in csv_stances:\n",
    "    body = bodies[int(row['Body ID'])]\n",
    "    if row['Stance'] == 'unrelated':\n",
    "        all_unrelated.append((row['Headline'], body, row['Stance']))\n",
    "    elif row['Stance'] == 'discuss':\n",
    "        all_discuss.append((row['Headline'], body, row['Stance']))\n",
    "    elif row['Stance'] == 'agree':\n",
    "        all_agree.append((row['Headline'], body, row['Stance']))\n",
    "    elif row['Stance'] == 'disagree':\n",
    "        all_disagree.append((row['Headline'], body, row['Stance']))\n",
    "f_stances.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train and validation 9:1\n",
    "print('\\tUnrltd\\tDiscuss\\t Agree\\tDisagree')\n",
    "print('All\\t', len(all_unrelated), '\\t', len(all_discuss), '\\t', len(all_agree), '\\t', len(all_disagree))\n",
    "\n",
    "train_unrelated = all_unrelated[:len(all_unrelated) * 9 // 10]\n",
    "train_discuss = all_discuss[:len(all_discuss) * 9 // 10]\n",
    "train_agree = all_agree[:len(all_agree) * 9 // 10]\n",
    "train_disagree = all_disagree[:len(all_disagree) * 9 // 10]\n",
    "\n",
    "val_unrelated = all_unrelated[len(all_unrelated) * 9 // 10:]\n",
    "val_discuss = all_discuss[len(all_discuss) * 9 // 10:]\n",
    "val_agree = all_agree[len(all_agree) * 9 // 10:]\n",
    "val_disagree = all_disagree[len(all_disagree) * 9 // 10:]\n",
    "\n",
    "print('Train\\t', len(train_unrelated), '\\t', len(train_discuss), '\\t', len(train_agree), '\\t', len(train_disagree))\n",
    "print('Valid.\\t', len(val_unrelated), '\\t', len(val_discuss), '\\t', len(val_agree), '\\t', len(val_disagree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = train_unrelated + train_discuss + train_agree + train_disagree  # each article = (headline, body, stance)\n",
    "random.Random(0).shuffle(train_all)\n",
    "train_all = np.array(train_all)\n",
    "\n",
    "val_all = val_unrelated + val_discuss + val_agree + val_disagree\n",
    "random.Random(0).shuffle(val_all)\n",
    "val_all = np.array(val_all)\n",
    "\n",
    "print('Train (Total)', train_all.shape, '\\tValidation (Total)', val_all.shape)\n",
    "print(np.count_nonzero(train_all[:, 2] == 'unrelated'), '\\t',\n",
    "      np.count_nonzero(train_all[:, 2] == 'discuss'), '\\t',\n",
    "      np.count_nonzero(train_all[:, 2] == 'agree'), '\\t',\n",
    "      np.count_nonzero(train_all[:, 2] == 'disagree'))\n",
    "print(np.count_nonzero(val_all[:, 2] == 'unrelated'), '\\t',\n",
    "      np.count_nonzero(val_all[:, 2] == 'discuss'), '\\t',\n",
    "      np.count_nonzero(val_all[:, 2] == 'agree'), '\\t',\n",
    "      np.count_nonzero(val_all[:, 2] == 'disagree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"[^a-zA-Z0-9 ]+\")  # strip punctuation, symbols, etc.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def tokenise(text):\n",
    "    # TODO remove stop words\n",
    "    text = pattern.sub('', text.replace('\\n', ' ').replace('-', ' ').lower())\n",
    "    text = [word for word in word_tokenize(text) if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "for i in range(9):\n",
    "    print(train_all[i, 0], tokenise(train_all[i, 0]))\n",
    "print(train_all[0, 1], tokenise(train_all[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_tf(text, ngram=1):\n",
    "    words = tokenise(text)\n",
    "    ret = defaultdict(float)\n",
    "    for i in range(len(words)):\n",
    "        for j in range(1, ngram+1):\n",
    "            if i - j < 0:\n",
    "                break\n",
    "            word = [words[i-k] for k in range(j)]\n",
    "            ret[word[0] if ngram == 1 else tuple(word)] += 1.0\n",
    "    return ret\n",
    "    \n",
    "for i in range(9):\n",
    "    print(train_all[i, 0], doc_to_tf(train_all[i, 0]))\n",
    "print(train_all[0, 1], doc_to_tf(train_all[0, 1]))\n",
    "print(doc_to_tf(train_all[0, 1], ngram=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build corpus of article bodies and headlines in training dataset\n",
    "corpus = np.r_[train_all[:, 1], train_all[:, 0]]  # 0 to 44973 are bodies, 44974 to 89943 are headlines\n",
    "\n",
    "print(corpus[0])\n",
    "print(corpus[44974])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn idf of every word in the corpus\n",
    "df = defaultdict(float)\n",
    "for doc in tqdm(corpus):\n",
    "    words = tokenise(doc)\n",
    "    seen = set()\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            df[word] += 1.0\n",
    "            seen.add(word)\n",
    "\n",
    "print(list(df.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = corpus.shape[0]\n",
    "idf = defaultdict(float)\n",
    "for word, val in tqdm(df.items()):\n",
    "    idf[word] = np.log((1.0 + num_docs) / (1.0 + val)) + 1.0  # smoothed idf\n",
    "\n",
    "print(list(idf.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GLoVe word vectors\n",
    "f_glove = open(\"data/glove.42B.300d.txt\", \"rb\")  # download from https://nlp.stanford.edu/projects/glove/\n",
    "glove_vectors = {}\n",
    "for line in tqdm(f_glove):\n",
    "    glove_vectors[str(line.split()[0]).split(\"'\")[1]] = np.array(list(map(float, line.split()[1:])))\n",
    "\n",
    "print(glove_vectors['glove'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a document to GloVe vectors, by computing tf-idf of each word * GLoVe of word / total tf-idf for document\n",
    "def doc_to_glove(doc):\n",
    "    doc_tf = doc_to_tf(doc)\n",
    "    doc_tf_idf = defaultdict(float)\n",
    "    for word, tf in doc_tf.items():\n",
    "        doc_tf_idf[word] = tf * idf[word]\n",
    "        \n",
    "    doc_vector = np.zeros(glove_vectors['glove'].shape[0])\n",
    "    if np.sum(list(doc_tf_idf.values())) == 0.0:  # edge case: document is empty\n",
    "        return doc_vector\n",
    "    \n",
    "    for word, tf_idf in doc_tf_idf.items():\n",
    "        if word in glove_vectors:\n",
    "            doc_vector += glove_vectors[word] * tf_idf\n",
    "    doc_vector /= np.sum(list(doc_tf_idf.values()))\n",
    "    return doc_vector\n",
    "\n",
    "for i in range(2):\n",
    "    print(train_all[i, 0], doc_to_glove(train_all[i, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity of GLoVe vectors for all headline-body pairs\n",
    "def dot_product(vec1, vec2):\n",
    "    sigma = 0.0\n",
    "    for i in range(vec1.shape[0]):  # assume vec1 and vec2 has same shape\n",
    "        sigma += vec1[i] * vec2[i]\n",
    "    return sigma\n",
    "    \n",
    "def magnitude(vec):\n",
    "    return np.sqrt(np.sum(np.square(vec)))\n",
    "        \n",
    "def cosine_similarity(doc):\n",
    "    headline_vector = doc_to_glove(doc[0])\n",
    "    body_vector = doc_to_glove(doc[1])\n",
    "    \n",
    "    if magnitude(headline_vector) == 0.0 or magnitude(body_vector) == 0.0:  # edge case: document is empty\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product(headline_vector, body_vector) / (magnitude(headline_vector) * magnitude(body_vector))\n",
    "\n",
    "for i in range(10):\n",
    "    # unrelated should have lower than rest\n",
    "    print(cosine_similarity(train_all[i]), train_all[i, 2])\n",
    "    \n",
    "print(cosine_similarity(train_all[27069]), tokenise(train_all[27069, 0]), tokenise(train_all[27069, 1]))  # edge case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the KL-Divergence of language model (LM) representations of the headline and the body\n",
    "def divergence(lm1, lm2):\n",
    "    sigma = 0.0\n",
    "    for i in range(lm1.shape[0]):  # assume lm1 and lm2 has same shape\n",
    "        sigma += lm1[i] * np.log(lm1[i] / lm2[i])\n",
    "    return sigma\n",
    "\n",
    "eps = 0.1  # add a small value for every common word in the LM, as KL-divergence won't work if there are 0 values\n",
    "def kl_divergence(doc):\n",
    "    # Convert headline and body to 1-gram representations\n",
    "    tf_headline = doc_to_tf(doc[0])\n",
    "    tf_body = doc_to_tf(doc[1])\n",
    "    \n",
    "    # Convert dictionary tf representations to vectors (make sure columns match to the same word)\n",
    "    words = set(tf_headline.keys()).union(set(tf_body.keys()))\n",
    "    vec_headline, vec_body = np.zeros(len(words)), np.zeros(len(words))\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        vec_headline[i] += tf_headline[word]\n",
    "        vec_body[i] = tf_body[word]\n",
    "        i += 1\n",
    "    \n",
    "    # Compute a simple 1-gram language model of headline and body\n",
    "    lm_headline = vec_headline + eps\n",
    "    lm_headline /= np.sum(lm_headline)\n",
    "    lm_body = vec_body + eps\n",
    "    lm_body /= np.sum(lm_body)\n",
    "    \n",
    "    # Return KL-divergence of both language models\n",
    "    return divergence(lm_headline, lm_body)\n",
    "\n",
    "for i in range(10):\n",
    "    # unrelated should have higher than rest\n",
    "    print(kl_divergence(train_all[i]), train_all[i, 2])\n",
    "    \n",
    "print(kl_divergence(train_all[27069]), tokenise(train_all[27069, 0]), tokenise(train_all[27069, 1]))  # edge case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other feature 1\n",
    "def ngram_match(doc):\n",
    "    # Returns how many times n-grams (up to 3-gram) that occur in the article's headline occur on the article's body.\n",
    "    tf_headline = doc_to_tf(doc[0], ngram=3)\n",
    "    tf_body = doc_to_tf(doc[1], ngram=3)\n",
    "    matches = 0.0\n",
    "    for words in tf_headline.keys():\n",
    "        if words in tf_body:\n",
    "            matches += tf_body[words]\n",
    "    return np.power((matches / len(tokenise(doc[1]))), 1 / np.e)  # normalise for document length\n",
    "\n",
    "for i in range(10):\n",
    "    # unrelated should have lower than rest\n",
    "    print(ngram_match(train_all[i]), train_all[i, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other feature 2\n",
    "def body_polarity(doc):\n",
    "    # TODO no. of polarised words e.g. 'no' in the body (should be lower for discuss compared to agree/disagree)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert (headline, body) to feature vectors for each document\n",
    "ftrs = [cosine_similarity, kl_divergence, ngram_match]\n",
    "def to_feature_array(doc):\n",
    "    vec = np.array([0.0] * len(ftrs))\n",
    "    for i in range(len(ftrs)):\n",
    "        vec[i] = ftrs[i](doc)\n",
    "    return vec\n",
    "\n",
    "# Initialise x (feature vectors) and y for train dataset\n",
    "x_train = np.array([to_feature_array(doc) for doc in tqdm(train_all)])\n",
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_to_int = {'agree': 0, 'disagree': 0, 'discuss': 0, 'unrelated': 1}\n",
    "# int_to_label = ['discuss', 'unrelated']\n",
    "label_to_int = {'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}\n",
    "int_to_label = ['agree', 'disagree', 'discuss', 'unrelated']\n",
    "y_train = np.array([label_to_int[i] for i in train_all[:, 2]])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check integrity of feature vectors\n",
    "print(np.where(np.isnan(x_train)))\n",
    "print(np.where(np.isfinite(x_train) == False))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GLoVe distance vs KL-Divergence on a coloured scatter plot with different colours for each label\n",
    "colours = np.array(['g', 'r', 'b', 'y'])\n",
    "plt.scatter(list(x_train[:, 0]), list(x_train[:, 1]), c=colours[y_train])\n",
    "plt.xlabel('Cosine Similarity of GLoVe vectors')\n",
    "plt.ylabel('KL Divergence of Unigram LMs')\n",
    "print([(colours[i], int_to_label[i]) for i in range(len(int_to_label))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise x (feature vectors) for validation dataset\n",
    "x_val = np.array([to_feature_array(doc) for doc in tqdm(val_all)])\n",
    "print(x_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "def mse(pred, gold):\n",
    "    sigma = 0.0\n",
    "    for i in range(pred.shape[0]):\n",
    "        sigma += np.square(pred[i] - gold[i])\n",
    "    return sigma / (2 * pred.shape[0])\n",
    "\n",
    "print(mse(np.array([0.0, 0.2, 0.5, 0.5, 0.8, 1.0]), np.array([0, 0, 0, 1, 1, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, lrn_rate, n_iter):\n",
    "        self.lrn_rate = lrn_rate\n",
    "        self.n_iter = n_iter\n",
    "        # self.breakpoints = set([n_iter * i // 10 for i in range(1, 11)])\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # Learn a model y = x0*t0 + x1*t1 + x2*t2 + ... that minimises MSE. Need to optimise T\n",
    "        self.model = np.zeros(X.shape[1])  # model[0] = t0, model[1] = t1, etc.\n",
    "        for it in tqdm(range(self.n_iter)):\n",
    "            model_Y = self.transform(X)\n",
    "            for col in range(X.shape[1]):\n",
    "                s = 0.0\n",
    "                for row in range(X.shape[0]):\n",
    "                    s += (model_Y[row] - Y[row]) * X[row, col]\n",
    "                self.model[col] -= self.lrn_rate * s / X.shape[0]\n",
    "            # if it + 1 in self.breakpoints:\n",
    "                # print('Iteration', it+1, 'MSE:', mse(model_Y, Y))\n",
    "        print('Final MSE:', mse(model_Y, Y))\n",
    "        print('Model:', self.model)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # Returns a float value for each X. (Regression)\n",
    "        Y = np.zeros(X.shape[0])\n",
    "        for row in range(X.shape[0]):\n",
    "            s = 0.0\n",
    "            for col in range(X.shape[1]):\n",
    "                s += self.model[col] * X[row, col]\n",
    "            Y[row] = s\n",
    "        return Y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Uses results of transform() for binary classification. For testing only, use OneVAllClassifier for the final run.\n",
    "        Y = self.transform(X)\n",
    "        Y = np.array([(1 if i > 0.5 else 0) for i in Y])\n",
    "        return Y\n",
    "\n",
    "# Test only\n",
    "lr = LinearRegression(lrn_rate=0.1, n_iter=100)\n",
    "lr.fit(x_train[:1000], np.array([(1 if i == 3 else 0) for i in y_train[:1000]]))\n",
    "# print(x_train[100:110])\n",
    "print(lr.transform(x_train[1000:1020]))\n",
    "print('Predicted', lr.predict(x_train[1000:1020]))\n",
    "print('Actual', np.array([(1 if i == 3 else 0) for i in y_train[1000:1020]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "def sigmoid(Y):\n",
    "    return 1 / (1 + np.exp(Y * -1))\n",
    "\n",
    "print(sigmoid(np.array([0.0, 0.2, 0.5, 0.5, 0.8, 1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_cost(pred, gold):\n",
    "    sigma = 0.0\n",
    "    for i in range(pred.shape[0]):\n",
    "        if gold[i] == 1:  \n",
    "            sigma -= np.log(pred[i])\n",
    "        elif gold[i] == 0:\n",
    "            sigma -= np.log(1 - pred[i])\n",
    "    return sigma / pred.shape[0]\n",
    "\n",
    "print(mse(np.array([0.0, 0.2, 0.5, 0.5, 0.8, 1.0]), np.array([0, 0, 0, 1, 1, 1])))\n",
    "print(logistic_cost(np.array([0.0, 0.2, 0.5, 0.5, 0.8, 1.0]), np.array([0, 0, 0, 1, 1, 1])))\n",
    "print(logistic_cost(sigmoid(np.array([0.0, 0.2, 0.5, 0.5, 0.8, 1.0])), np.array([0, 0, 0, 1, 1, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, lrn_rate, n_iter):\n",
    "        self.lrn_rate = lrn_rate\n",
    "        self.n_iter = n_iter\n",
    "        # self.breakpoints = set([n_iter * i // 10 for i in range(1, 11)])\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # Learn a model y = x0*t0 + x1*t1 + x2*t2 + ... that minimises MSE. Need to optimise T\n",
    "        self.model = np.zeros(X.shape[1])  # model[0] = t0, model[1] = t1, etc.\n",
    "        for it in tqdm(range(self.n_iter)):\n",
    "            model_Y = self.transform(X)\n",
    "            for col in range(X.shape[1]):\n",
    "                s = 0.0\n",
    "                for row in range(X.shape[0]):\n",
    "                    s += (model_Y[row] - Y[row]) * X[row, col]\n",
    "                self.model[col] -= self.lrn_rate * s / X.shape[0]\n",
    "            # if it + 1 in self.breakpoints:\n",
    "                # print('Iteration', it+1, 'loss:', logistic_cost(model_Y, Y))\n",
    "        print('Final loss:', logistic_cost(model_Y, Y))\n",
    "        print('Model:', self.model)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # Returns a float value for each X. (Regression)\n",
    "        Y = np.zeros(X.shape[0])\n",
    "        for row in range(X.shape[0]):\n",
    "            s = 0.0\n",
    "            for col in range(X.shape[1]):\n",
    "                s += self.model[col] * X[row, col]\n",
    "            Y[row] = s\n",
    "        return sigmoid(Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Uses results of transform() for binary classification. For testing only, use OneVAllClassifier for the final run.\n",
    "        Y = self.transform(X)\n",
    "        Y = np.array([(1 if i > 0.5 else 0) for i in Y])\n",
    "        return Y\n",
    "\n",
    "# Test only\n",
    "lr = LogisticRegression(lrn_rate=0.1, n_iter=100)\n",
    "lr.fit(x_train[:1000], np.array([(1 if i == 3 else 0) for i in y_train[:1000]]))\n",
    "# print(x_train[100:110])\n",
    "print(lr.transform(x_train[1000:1020]))\n",
    "print('Predicted', lr.predict(x_train[1000:1020]))\n",
    "print('Actual', np.array([(1 if i == 3 else 0) for i in y_train[1000:1020]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use linear/logistic models to classify multiple classes\n",
    "class OneVAllClassifier:\n",
    "    \n",
    "    def __init__(self, regression, **params):\n",
    "        self.regression = regression\n",
    "        self.params = params\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # Learn a model for each parameter.\n",
    "        self.categories = np.unique(Y)\n",
    "        self.models = {}\n",
    "        for cat in self.categories:\n",
    "            ova_Y = np.array([(1 if i == cat else 0) for i in Y])\n",
    "            model = self.regression(**self.params)\n",
    "            model.fit(X, ova_Y)\n",
    "            self.models[cat] = model\n",
    "            print(int_to_label[cat])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predicts each x for each different model learned, and returns the category related to the model with the highest score.\n",
    "        vals = {}\n",
    "        for cat, model in self.models.items():\n",
    "            vals[cat] = model.transform(X)\n",
    "        Y = np.zeros(X.shape[0], dtype=np.int)\n",
    "        for row in range(X.shape[0]):\n",
    "            max_val, max_cat = -math.inf, -math.inf\n",
    "            for cat, val in vals.items():\n",
    "                if val[row] > max_val:\n",
    "                    max_val, max_cat = val[row], cat\n",
    "            Y[row] = max_cat\n",
    "        return Y\n",
    "    \n",
    "# Test only\n",
    "ova = OneVAllClassifier(LogisticRegression, lrn_rate=0.1, n_iter=100)\n",
    "ova.fit(x_train[:1000], y_train[:1000])\n",
    "print('Predicted', ova.predict(x_train[1000:1020]))\n",
    "print('Actual', y_train[1000:1020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVAllClassifier(LinearRegression, lrn_rate=0.1, n_iter=1000)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y for validation set\n",
    "y_pred = clf.predict(x_val)\n",
    "print(y_pred[:5])\n",
    "predicted = np.array([int_to_label[i] for i in y_pred])\n",
    "print(predicted[:5])\n",
    "print(val_all[:, 2][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset format for score_submission in scorer.py\n",
    "body_ids = [str(body_inverse_index[body]) for body in val_all[:, 1]]\n",
    "pred_for_cm = np.array([{'Headline': val_all[i, 0], 'Body ID': body_ids[i], 'Stance': predicted[i]} for i in range(len(val_all))])\n",
    "gold_for_cm = np.array([{'Headline': val_all[i, 0], 'Body ID': body_ids[i], 'Stance': val_all[i, 2]} for i in range(len(val_all))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score using scorer.py (provided in https://github.com/FakeNewsChallenge/fnc-1) on VALIDATION set:\n",
    "test_score, cm = score_submission(gold_for_cm, pred_for_cm)\n",
    "null_score, max_score = score_defaults(gold_for_cm)\n",
    "print_confusion_matrix(cm)\n",
    "print(SCORE_REPORT.format(max_score, null_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO score using scorer.py on TEST set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO analyse importance of each feature \n",
    "# (easiest: for each feature, re-run everything without that feature & see how much the score decreases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier(n_estimators=200)\n",
    "ACCURACY: 0.834  ||  1604.25  ||  No Added Features (just Cosine and KL-Divergence)\n",
    "ACCURACY: 0.861  ||  1743.5   ||  'Raw' Unigram Match\n",
    "ACCURACY: 0.861  ||  1743.5   ||  1+log(x) Unigram Match\n",
    "ACCURACY: 0.860  ||  1743.5   ||  1-1/e^(x/2) Unigram Match\n",
    "ACCURACY: 0.884  ||  1834.5   ||  x/len(body) Unigram Match\n",
    "ACCURACY: 0.873  ||  1790.5   ||  log(x)/log(len(body)) Unigram Match\n",
    "ACCURACY: 0.884  ||  1834.25  ||  (x/len(body))^1/e Unigram Match\n",
    "    \n",
    "LogisticRegression(C=1e5)\n",
    "ACCURACY: 0.880  ||  1795.5   ||  (x/len(body))^1/e Unigram Match\n",
    "\n",
    "LogisticRegression(C=1e2, multi_class='multinomial', solver='saga')\n",
    "ACCURACY: 0.881  ||  1818.5   ||  (x/len(body))^1/e Unigram Match\n",
    "ACCURACY: 0.882  ||  1819.5   ||  (x/len(body))^1/e 2-gram Match\n",
    "ACCURACY: 0.882  ||  1820.5   ||  (x/len(body))^1/e 3-gram Match\n",
    "    \n",
    "My own features, sklearns LogisticRegression(...'saga') still: (+time to compute x_train)\n",
    "0.829, 1581.5 (Without Stop Word Removal. 50d GLoVe Wikipedia)\n",
    "0.878, 1801.5, 9:20 (With Stop Word Removal. 50d GLoVe Wikipedia)\n",
    "0.879, 1802.0, 9:13 (With Stop Word Removal. 300d GLoVe Wikipedia)\n",
    "0.879, 1802.0,  (With Stop Word Removal. 300d GLoVe Common Crawl)\n",
    "\n",
    "My own regression algo:\n",
    "Predict everything as unrelated: 0.731, 914.5\n",
    "Simple linear regression (no intercept) (lr 0.1, n_it 100): 0.796, 1573.0\n",
    "Simple linear regression (lr 0.1, n_it 1000): 0.859, 1787.25\n",
    "1vA linear regression, discuss/unrelated only (lr 0.1, n_it 1000): 0.859, 1787.25 - nvm wrong (predict over transform) try again\n",
    "1vA linear regression, all 4 categories (lr 0.1, n_it 1000): 0.821, 1644.0 - nvm wrong (predict over transform) try again\n",
    "1vA linear regression, all 4 categories (lr 0.1, n_it 1000): 0.871, 1739.0\n",
    "1vA logistic regression, all 4 categories (lr 0.1, n_it 1000): 0.819, 1545.5 - nvm wrong (predict over transform) try again\n",
    "1vA logistic regression, all 4 categories (lr 0.1, n_it 1000): 0.844, 1572.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
